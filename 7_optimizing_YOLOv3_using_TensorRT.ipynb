{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed libraries\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "from tensorflow.python.platform import gfile\n",
    "from PIL import Image\n",
    "from YOLOv3 import utils\n",
    "\n",
    "# config\n",
    "SIZE = [416, 416] #input image dimension\n",
    "# video_path = 0 # if you use camera as input\n",
    "video_path = \"./dataset/demo_video/road2.mp4\" # path for video input\n",
    "classes = utils.read_coco_names('./YOLOv3/coco.names')\n",
    "num_classes = len(classes)\n",
    "GIVEN_ORIGINAL_YOLOv3_MODEL = \"./YOLOv3/yolov3_gpu_nms.pb\" # to use given original YOLOv3\n",
    "TENSORRT_YOLOv3_MODEL = \"./YOLOv3/TensorRT_YOLOv3.pb\" # to use the TensorRT optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vid = cv2.VideoCapture(video_path)\n",
    "#return_value, frame = vid.read()\n",
    "#cv2.imshow(\"cek\", frame)\n",
    "\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cvrc/TensorRT/YOLOv3/utils.py:225: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n",
      "ret: False\n"
     ]
    }
   ],
   "source": [
    "# get input-output tensor\n",
    "input_tensor, output_tensors = utils.read_pb_return_tensors(tf.get_default_graph(),\n",
    "                                                            TENSORRT_YOLOv3_MODEL,\n",
    "                                                            [\"Placeholder:0\", \"concat_9:0\", \"mul_9:0\"])\n",
    "\n",
    "# perform inference\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.5))) as sess:\n",
    "    vid = cv2.VideoCapture(video_path) # must use opencv >= 3.3.1 (install it by 'pip install opencv-python')\n",
    "    while True:\n",
    "        return_value, frame = vid.read()\n",
    "        #print(\"return:\", return_value, \"; shape:\", frame)\n",
    "        #return_value = True\n",
    "        #frame = cv2.imread('./pictures/dog.jpg', 1)\n",
    "        if return_value == False:\n",
    "            print('ret:', return_value)\n",
    "            #vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            vid = cv2.VideoCapture(video_path)\n",
    "            return_value, frame = vid.read()\n",
    "        if return_value:\n",
    "            image = Image.fromarray(frame)\n",
    "        else:\n",
    "            raise ValueError(\"No image!\")\n",
    "            \n",
    "        img_resized = np.array(image.resize(size=tuple(SIZE)), dtype=np.float32)\n",
    "        img_resized = img_resized / 255.\n",
    "        prev_time = time.time()\n",
    "\n",
    "        boxes, scores = sess.run(output_tensors, feed_dict={input_tensor: np.expand_dims(img_resized, axis=0)})\n",
    "        boxes, scores, labels = utils.cpu_nms(boxes, scores, num_classes, score_thresh=0.4, iou_thresh=0.5)\n",
    "        image = utils.draw_boxes(image, boxes, scores, labels, classes, SIZE, show=False)\n",
    "\n",
    "        curr_time = time.time()\n",
    "        exec_time = curr_time - prev_time\n",
    "        result = np.asarray(image)\n",
    "        info = \"time:\" + str(round(1000*exec_time, 2)) + \" ms, FPS: \" + str(round((1000/(1000*exec_time)),1))\n",
    "        cv2.putText(result, text=info, org=(50, 70), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=1, color=(255, 0, 0), thickness=2)\n",
    "        #cv2.namedWindow(\"result\", cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow(\"result\", result)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'): break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize given YOLOv3 model using TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read a \".pb\" model \n",
    "def read_pb_graph(model):\n",
    "  with gfile.FastGFile(model,'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "  return graph_def\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.30))) as sess:\n",
    "    frozen_graph = read_pb_graph(\"./YOLOv3/yolov3_gpu_nms.pb\")\n",
    "    \n",
    "    # convert (optimize) frozen model to TensorRT model\n",
    "    your_outputs = [\"Placeholder:0\", \"concat_9:0\", \"mul_9:0\"]\n",
    "    trt_graph = trt.create_inference_graph(\n",
    "        input_graph_def=frozen_graph,# frozen model\n",
    "        outputs=your_outputs,\n",
    "        max_batch_size=1,# specify your max batch size\n",
    "        max_workspace_size_bytes=3*(10**9),# specify the max workspace\n",
    "        precision_mode=\"FP16\") # precision, can be \"FP32\" (32 floating point precision) or \"FP16\"\n",
    "    print(\"The model is already converted to TensorRT graph\")\n",
    "\n",
    "    #write the TensorRT model to be used later for inference\n",
    "    with gfile.FastGFile(\"./YOLOv3/TensorRT_YOLOv3.pb\", 'wb') as f:\n",
    "        f.write(trt_graph.SerializeToString())\n",
    "    print(\"TensorRT YOLOv3 model is successfully stored!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TF1120_GPU]",
   "language": "python",
   "name": "conda-env-TF1120_GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
